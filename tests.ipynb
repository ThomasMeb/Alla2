{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=200\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/btc_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volumefrom</th>\n",
       "      <th>volumeto</th>\n",
       "      <th>close</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>progression daily</th>\n",
       "      <th>progression tomorrow</th>\n",
       "      <th>target</th>\n",
       "      <th>ema_26</th>\n",
       "      <th>ema_12</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi</th>\n",
       "      <th>relative_volume</th>\n",
       "      <th>obv</th>\n",
       "      <th>atr</th>\n",
       "      <th>bollinger_upper</th>\n",
       "      <th>bollinger_lower</th>\n",
       "      <th>k</th>\n",
       "      <th>momentum</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>2821.24</td>\n",
       "      <td>8.419500e+02</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251628</td>\n",
       "      <td>0.272215</td>\n",
       "      <td>0.020587</td>\n",
       "      <td>75.041736</td>\n",
       "      <td>0.433468</td>\n",
       "      <td>5.683560e+03</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.302597</td>\n",
       "      <td>0.209763</td>\n",
       "      <td>98.360656</td>\n",
       "      <td>0.060</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-02</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>5352.11</td>\n",
       "      <td>1.584660e+03</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.255211</td>\n",
       "      <td>0.276490</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>74.831650</td>\n",
       "      <td>0.784203</td>\n",
       "      <td>4.098900e+03</td>\n",
       "      <td>0.018214</td>\n",
       "      <td>0.307253</td>\n",
       "      <td>0.213107</td>\n",
       "      <td>98.360656</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>1425.19</td>\n",
       "      <td>4.208500e+02</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258529</td>\n",
       "      <td>0.280107</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>75.402884</td>\n",
       "      <td>0.227126</td>\n",
       "      <td>3.678050e+03</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.311694</td>\n",
       "      <td>0.215676</td>\n",
       "      <td>98.360656</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>1879.00</td>\n",
       "      <td>5.483300e+02</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>0.282398</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>0.317246</td>\n",
       "      <td>3.129720e+03</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.315355</td>\n",
       "      <td>0.216845</td>\n",
       "      <td>90.163934</td>\n",
       "      <td>0.047</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.2989</td>\n",
       "      <td>357.16</td>\n",
       "      <td>1.061900e+02</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013220</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264021</td>\n",
       "      <td>0.284937</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>90.397805</td>\n",
       "      <td>0.063656</td>\n",
       "      <td>3.235910e+03</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.318771</td>\n",
       "      <td>0.219319</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13</th>\n",
       "      <td>27110.9100</td>\n",
       "      <td>26674.970</td>\n",
       "      <td>26756.2300</td>\n",
       "      <td>18507.04</td>\n",
       "      <td>4.967794e+08</td>\n",
       "      <td>26862.9000</td>\n",
       "      <td>5.216077e+11</td>\n",
       "      <td>-0.004279</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>1</td>\n",
       "      <td>27129.215560</td>\n",
       "      <td>27294.402418</td>\n",
       "      <td>165.186858</td>\n",
       "      <td>46.835697</td>\n",
       "      <td>0.904417</td>\n",
       "      <td>1.270529e+10</td>\n",
       "      <td>785.304286</td>\n",
       "      <td>28397.807436</td>\n",
       "      <td>25925.062564</td>\n",
       "      <td>10.940893</td>\n",
       "      <td>-750.990</td>\n",
       "      <td>5.732151e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-14</th>\n",
       "      <td>26982.7800</td>\n",
       "      <td>26810.020</td>\n",
       "      <td>26862.9000</td>\n",
       "      <td>5865.21</td>\n",
       "      <td>1.576854e+08</td>\n",
       "      <td>26854.5200</td>\n",
       "      <td>5.236556e+11</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0</td>\n",
       "      <td>27109.488482</td>\n",
       "      <td>27228.017431</td>\n",
       "      <td>118.528949</td>\n",
       "      <td>49.455572</td>\n",
       "      <td>0.288510</td>\n",
       "      <td>1.286298e+10</td>\n",
       "      <td>786.607857</td>\n",
       "      <td>28390.511290</td>\n",
       "      <td>25960.107710</td>\n",
       "      <td>16.135237</td>\n",
       "      <td>-565.760</td>\n",
       "      <td>5.732151e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-15</th>\n",
       "      <td>27297.2600</td>\n",
       "      <td>26813.060</td>\n",
       "      <td>26854.5200</td>\n",
       "      <td>10978.68</td>\n",
       "      <td>2.971100e+08</td>\n",
       "      <td>27177.4100</td>\n",
       "      <td>5.239792e+11</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>1</td>\n",
       "      <td>27090.601927</td>\n",
       "      <td>27170.556287</td>\n",
       "      <td>79.954360</td>\n",
       "      <td>48.700891</td>\n",
       "      <td>0.555745</td>\n",
       "      <td>1.256587e+10</td>\n",
       "      <td>738.972857</td>\n",
       "      <td>28353.377450</td>\n",
       "      <td>26056.549550</td>\n",
       "      <td>15.727169</td>\n",
       "      <td>-935.280</td>\n",
       "      <td>5.732151e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-16</th>\n",
       "      <td>30009.1500</td>\n",
       "      <td>27131.480</td>\n",
       "      <td>27177.4100</td>\n",
       "      <td>66720.48</td>\n",
       "      <td>1.884463e+09</td>\n",
       "      <td>28518.3700</td>\n",
       "      <td>5.296435e+11</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>1</td>\n",
       "      <td>27097.032155</td>\n",
       "      <td>27171.610705</td>\n",
       "      <td>74.578550</td>\n",
       "      <td>38.382575</td>\n",
       "      <td>3.228924</td>\n",
       "      <td>1.445033e+10</td>\n",
       "      <td>848.527857</td>\n",
       "      <td>28315.553845</td>\n",
       "      <td>26182.321155</td>\n",
       "      <td>18.572004</td>\n",
       "      <td>-237.180</td>\n",
       "      <td>5.732151e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-17</th>\n",
       "      <td>28613.2400</td>\n",
       "      <td>28094.140</td>\n",
       "      <td>28518.3700</td>\n",
       "      <td>10541.85</td>\n",
       "      <td>2.990360e+08</td>\n",
       "      <td>28348.8300</td>\n",
       "      <td>5.553388e+11</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>-0.005945</td>\n",
       "      <td>0</td>\n",
       "      <td>27202.316440</td>\n",
       "      <td>27378.804442</td>\n",
       "      <td>176.488003</td>\n",
       "      <td>61.568243</td>\n",
       "      <td>0.533373</td>\n",
       "      <td>1.474937e+10</td>\n",
       "      <td>892.198571</td>\n",
       "      <td>28457.319281</td>\n",
       "      <td>26271.133719</td>\n",
       "      <td>57.131930</td>\n",
       "      <td>571.760</td>\n",
       "      <td>6.103068e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4673 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  high        low        open  volumefrom      volumeto  \\\n",
       "2011-01-01      0.3000      0.292      0.3000     2821.24  8.419500e+02   \n",
       "2011-01-02      0.3000      0.289      0.3000     5352.11  1.584660e+03   \n",
       "2011-01-03      0.3000      0.290      0.3000     1425.19  4.208500e+02   \n",
       "2011-01-04      0.2999      0.289      0.2950     1879.00  5.483300e+02   \n",
       "2011-01-05      0.2990      0.290      0.2989      357.16  1.061900e+02   \n",
       "...                ...        ...         ...         ...           ...   \n",
       "2023-10-13  27110.9100  26674.970  26756.2300    18507.04  4.967794e+08   \n",
       "2023-10-14  26982.7800  26810.020  26862.9000     5865.21  1.576854e+08   \n",
       "2023-10-15  27297.2600  26813.060  26854.5200    10978.68  2.971100e+08   \n",
       "2023-10-16  30009.1500  27131.480  27177.4100    66720.48  1.884463e+09   \n",
       "2023-10-17  28613.2400  28094.140  28518.3700    10541.85  2.990360e+08   \n",
       "\n",
       "                 close    market_cap  progression daily  progression tomorrow  \\\n",
       "2011-01-01      0.3000           NaN           0.000000              0.000000   \n",
       "2011-01-02      0.3000           NaN           0.000000              0.000000   \n",
       "2011-01-03      0.2950           NaN           0.000000             -0.016667   \n",
       "2011-01-04      0.2989           NaN          -0.016667              0.013220   \n",
       "2011-01-05      0.2990           NaN           0.013220              0.000335   \n",
       "...                ...           ...                ...                   ...   \n",
       "2023-10-13  26862.9000  5.216077e+11          -0.004279              0.003987   \n",
       "2023-10-14  26854.5200  5.236556e+11           0.003987             -0.000312   \n",
       "2023-10-15  27177.4100  5.239792e+11          -0.000312              0.012024   \n",
       "2023-10-16  28518.3700  5.296435e+11           0.012024              0.049341   \n",
       "2023-10-17  28348.8300  5.553388e+11           0.049341             -0.005945   \n",
       "\n",
       "            target        ema_26        ema_12        macd        rsi  \\\n",
       "2011-01-01       0      0.251628      0.272215    0.020587  75.041736   \n",
       "2011-01-02       0      0.255211      0.276490    0.021279  74.831650   \n",
       "2011-01-03       0      0.258529      0.280107    0.021578  75.402884   \n",
       "2011-01-04       1      0.261230      0.282398    0.021168  64.583333   \n",
       "2011-01-05       1      0.264021      0.284937    0.020916  90.397805   \n",
       "...            ...           ...           ...         ...        ...   \n",
       "2023-10-13       1  27129.215560  27294.402418  165.186858  46.835697   \n",
       "2023-10-14       0  27109.488482  27228.017431  118.528949  49.455572   \n",
       "2023-10-15       1  27090.601927  27170.556287   79.954360  48.700891   \n",
       "2023-10-16       1  27097.032155  27171.610705   74.578550  38.382575   \n",
       "2023-10-17       0  27202.316440  27378.804442  176.488003  61.568243   \n",
       "\n",
       "            relative_volume           obv         atr  bollinger_upper  \\\n",
       "2011-01-01         0.433468  5.683560e+03    0.018136         0.302597   \n",
       "2011-01-02         0.784203  4.098900e+03    0.018214         0.307253   \n",
       "2011-01-03         0.227126  3.678050e+03    0.016429         0.311694   \n",
       "2011-01-04         0.317246  3.129720e+03    0.015286         0.315355   \n",
       "2011-01-05         0.063656  3.235910e+03    0.014000         0.318771   \n",
       "...                     ...           ...         ...              ...   \n",
       "2023-10-13         0.904417  1.270529e+10  785.304286     28397.807436   \n",
       "2023-10-14         0.288510  1.286298e+10  786.607857     28390.511290   \n",
       "2023-10-15         0.555745  1.256587e+10  738.972857     28353.377450   \n",
       "2023-10-16         3.228924  1.445033e+10  848.527857     28315.553845   \n",
       "2023-10-17         0.533373  1.474937e+10  892.198571     28457.319281   \n",
       "\n",
       "            bollinger_lower          k  momentum    difficulty  \n",
       "2011-01-01         0.209763  98.360656     0.060           NaN  \n",
       "2011-01-02         0.213107  98.360656     0.050           NaN  \n",
       "2011-01-03         0.215676  98.360656     0.050           NaN  \n",
       "2011-01-04         0.216845  90.163934     0.047           NaN  \n",
       "2011-01-05         0.219319  96.500000     0.049           NaN  \n",
       "...                     ...        ...       ...           ...  \n",
       "2023-10-13     25925.062564  10.940893  -750.990  5.732151e+13  \n",
       "2023-10-14     25960.107710  16.135237  -565.760  5.732151e+13  \n",
       "2023-10-15     26056.549550  15.727169  -935.280  5.732151e+13  \n",
       "2023-10-16     26182.321155  18.572004  -237.180  5.732151e+13  \n",
       "2023-10-17     26271.133719  57.131930   571.760  6.103068e+13  \n",
       "\n",
       "[4673 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4673.000000\n",
       "mean     10010.712764\n",
       "std      14842.749681\n",
       "min          0.295000\n",
       "25%        237.410000\n",
       "50%       2052.430000\n",
       "75%      11657.810000\n",
       "max      67549.140000\n",
       "Name: open, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['open'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les caractéristiques et exclure la dernière ligne\n",
    "features = data.drop(columns=['progression tomorrow', 'target', 'close', 'high', 'low', 'volumefrom', 'market_cap', 'difficulty']).iloc[:-1, :]\n",
    "target = data['target'].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la taille de la fenêtre initiale\n",
    "window_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  \\n# Initialiser les listes pour stocker les prédictions et les vraies valeurs\\npredictions = []\\nactuals = []\\n\\n# Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\\nfor i in range(window_size, len(data) - 1):\\n    # Diviser les données en ensembles d'entraînement et de test\\n    X_train = features.iloc[i-window_size:i, :]\\n    y_train = target.iloc[i-window_size:i]\\n    X_test = features.iloc[i:i+1, :]\\n    y_test = target.iloc[i]\\n\\n    #Normaliser les données\\n    scaler = StandardScaler()\\n    X_train_train = scaler.fit_transform(X_train)\\n    X_test = scaler.transform(X_test)\\n    \\n    # Entraîner un modèle\\n    model = RandomForestClassifier()\\n    model.fit(X_train, y_train)\\n    \\n    # Faire une prédiction\\n    prediction = model.predict(X_test)[0]\\n    \\n    # Stocker les prédictions et les vraies valeurs\\n    predictions.append(prediction)\\n    actuals.append(y_test)\\n\\n# Évaluer le modèle\\naccuracy = accuracy_score(actuals, predictions)\\nprint(f'Model Accuracy: {accuracy * 100:.2f}%')\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test avec RandomForest\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"  \n",
    "# Initialiser les listes pour stocker les prédictions et les vraies valeurs\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "# Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\n",
    "for i in range(window_size, len(data) - 1):\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    X_train = features.iloc[i-window_size:i, :]\n",
    "    y_train = target.iloc[i-window_size:i]\n",
    "    X_test = features.iloc[i:i+1, :]\n",
    "    y_test = target.iloc[i]\n",
    "\n",
    "    #Normaliser les données\n",
    "    scaler = StandardScaler()\n",
    "    X_train_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Entraîner un modèle\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faire une prédiction\n",
    "    prediction = model.predict(X_test)[0]\n",
    "    \n",
    "    # Stocker les prédictions et les vraies valeurs\n",
    "    predictions.append(prediction)\n",
    "    actuals.append(y_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data, model, features, target, window_size):\n",
    "      \n",
    "      # Initialiser les listes pour stocker les prédictions et les vraies valeurs\n",
    "      predictions = []\n",
    "      actuals = []\n",
    "\n",
    "      # Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\n",
    "      for i in range(window_size, len(data) - 1):\n",
    "            # Diviser les données en ensembles d'entraînement et de test\n",
    "            X_train = features.iloc[i-window_size:i, :]\n",
    "            y_train = target.iloc[i-window_size:i]\n",
    "            X_test = features.iloc[i:i+1, :]\n",
    "            y_test = target.iloc[i]\n",
    "\n",
    "            #Normaliser les données\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # Entraîner un modèle\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire une prédiction\n",
    "            prediction = model.predict(X_test)[0]\n",
    "            \n",
    "            # Stocker les prédictions et les vraies valeurs\n",
    "            predictions.append(prediction)\n",
    "            actuals.append(y_test)\n",
    "\n",
    "      # Évaluer le modèle\n",
    "      accuracy = accuracy_score(actuals, predictions)\n",
    "      print(f'Model Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 52.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "train_model(data, dummy_model, features, target, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 56.26%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression()\n",
    "train_model(data, logistic_regression, features, target, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, feature_names):\n",
    "    # Récupérer les coefficients du modèle\n",
    "    coefficients = model.coef_[0]\n",
    "    \n",
    "    # Créer un DataFrame pour stocker les caractéristiques et leurs importances\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': coefficients\n",
    "    })\n",
    "    \n",
    "    # Trier le DataFrame en fonction de l'importance\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', key=abs, ascending=False)\n",
    "    \n",
    "    # Visualiser l'importance des caractéristiques\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    plt.xlabel('Coefficient Value')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance for Logistic Regression')\n",
    "    plt.gca().invert_yaxis()  # Pour afficher la caractéristique la plus importante en haut\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importance(logistic_regression, features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.6904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def train_model_proba(data, model, features, target, window_size):\n",
    "      \n",
    "    # Initialiser les listes pour stocker les probabilités prédites et les vraies valeurs\n",
    "    predicted_probs = []\n",
    "    actuals = []\n",
    "\n",
    "    # Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\n",
    "    for i in range(window_size, len(data) - 1):\n",
    "        # Diviser les données en ensembles d'entraînement et de test\n",
    "        X_train = features.iloc[i-window_size:i, :]\n",
    "        y_train = target.iloc[i-window_size:i]\n",
    "        X_test = features.iloc[i:i+1, :]\n",
    "        y_test = target.iloc[i]\n",
    "\n",
    "        # Normaliser les données\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Entraîner un modèle\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Obtenir les probabilités prédites pour la classe positive (par exemple, 1)\n",
    "        prediction_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Stocker les probabilités prédites et les vraies valeurs\n",
    "        predicted_probs.extend(prediction_prob)\n",
    "        actuals.append(y_test)\n",
    "\n",
    "    # Calculer la Log Loss\n",
    "    loss = log_loss(actuals, predicted_probs)\n",
    "    print(f'Log Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.6904\n"
     ]
    }
   ],
   "source": [
    "train_model_proba(data, logistic_regression, features, target, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earn_metric(predicted_probs, n_days, c):\n",
    "      base = c\n",
    "      progressions = []\n",
    "      for i in range(n_days+1):\n",
    "            progressions.append(data.iloc[window_size+i]['progression tomorrow']+1)\n",
    "\n",
    "            c *= predicted_probs[i] * progressions[i] + (1 - predicted_probs[i])\n",
    "\n",
    "      return c / base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def train_model_proba_metric(data, model, features, target, window_size):\n",
    "      \n",
    "    # Initialiser les listes pour stocker les probabilités prédites et les vraies valeurs\n",
    "    predicted_probs = []\n",
    "    actuals = []\n",
    "    earnings = []\n",
    "\n",
    "    # Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\n",
    "    for i in range(window_size, len(data) - 1):\n",
    "        # Diviser les données en ensembles d'entraînement et de test\n",
    "        X_train = features.iloc[i-window_size:i, :]\n",
    "        y_train = target.iloc[i-window_size:i]\n",
    "        X_test = features.iloc[i:i+1, :]\n",
    "        y_test = target.iloc[i]\n",
    "\n",
    "        # Normaliser les données\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Entraîner un modèle\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Obtenir les probabilités prédites pour la classe positive (par exemple, 1)\n",
    "        prediction_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Stocker les probabilités prédites et les vraies valeurs\n",
    "        predicted_probs.extend(prediction_prob)\n",
    "        actuals.append(y_test)\n",
    "\n",
    "    # Calculer la Log Loss\n",
    "    loss = log_loss(actuals, predicted_probs)\n",
    "    print(f'Log Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132.33886546544136\n",
      "150.91903719912486\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "# Initialiser les listes pour stocker les probabilités prédites et les vraies valeurs\n",
    "predicted_probs = []\n",
    "actuals = []\n",
    "progressions = []\n",
    "\n",
    "c = 100\n",
    "base = 100\n",
    "\n",
    "for i in range(31):\n",
    "      # Diviser les données en ensembles d'entraînement et de test\n",
    "      X_train = features.iloc[i:window_size+i, :]\n",
    "      y_train = target.iloc[i:window_size+i]\n",
    "      X_test = features.iloc[window_size+i : window_size+i+1, :]\n",
    "      y_test = target.iloc[window_size+i]\n",
    "\n",
    "      # Normaliser les données\n",
    "      scaler = StandardScaler()\n",
    "      X_train_scaled = scaler.fit_transform(X_train)\n",
    "      X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "      # Entraîner un modèle\n",
    "      model.fit(X_train_scaled, y_train)\n",
    "\n",
    "      # Obtenir les probabilités prédites pour la classe positive (par exemple, 1)\n",
    "      prediction_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "      # Stocker les probabilités prédites et les vraies valeurs\n",
    "      predicted_probs.extend(prediction_prob)\n",
    "      actuals.append(y_test)\n",
    "      progressions.append(data.iloc[window_size+i]['progression tomorrow']+1)\n",
    "\n",
    "      c *= predicted_probs[i] * progressions[i] + (1 - predicted_probs[i])\n",
    "      base *= progressions[i]\n",
    "\n",
    "print(c)\n",
    "print(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.013347921225383,\n",
       " 1.0256963938674153,\n",
       " 1.0096842105263157,\n",
       " 0.9862385321100919,\n",
       " 0.988724453840733,\n",
       " 0.8766928011404134,\n",
       " 1.064959349593496,\n",
       " 1.044507214291167,\n",
       " 0.9991229352433855,\n",
       " 1.0080468178493052,\n",
       " 0.9854862119013063,\n",
       " 1.005081001472754,\n",
       " 1.0220528976481793,\n",
       " 1.0065232974910394,\n",
       " 0.9977921800441564,\n",
       " 1.0199143468950749,\n",
       " 1.032472531317797,\n",
       " 1.0260286043516573,\n",
       " 1.0443945299597013,\n",
       " 0.9666645581630717,\n",
       " 1.0312131919905771,\n",
       " 1.0678342534424774,\n",
       " 1.0883646303779415,\n",
       " 1.016107016107016,\n",
       " 1.0358946802794198,\n",
       " 1.0529619255109453,\n",
       " 1.1230602492733632,\n",
       " 0.9079264815545905,\n",
       " 0.956034399458885,\n",
       " 0.9529007479280373,\n",
       " 1.0973165040305473]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.60040721080683,\n",
       " 0.479947056414951,\n",
       " 0.548275436829798,\n",
       " 0.4563232295849949,\n",
       " 0.4422230635316302,\n",
       " 0.4140664330528999,\n",
       " 0.4361871849836109,\n",
       " 0.43460689675727876,\n",
       " 0.3887822819149118,\n",
       " 0.37363990309366896,\n",
       " 0.387200441772941,\n",
       " 0.4055367094480023,\n",
       " 0.4258094386710644,\n",
       " 0.39559626208842863,\n",
       " 0.37528370294677327,\n",
       " 0.3506205662074579,\n",
       " 0.2927787947594506,\n",
       " 0.3714842412223311,\n",
       " 0.4105885437975299,\n",
       " 0.5173820022615735,\n",
       " 0.6836440433816976,\n",
       " 0.704059632038982,\n",
       " 0.7912445607844866,\n",
       " 0.6580611503646457,\n",
       " 0.6503088615065241,\n",
       " 0.6730367978693366,\n",
       " 0.7328463246790808,\n",
       " 0.591138581770577,\n",
       " 0.5713847961102692,\n",
       " 0.5889210519426863,\n",
       " 0.5655505962196752]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "c *= (progressions[0]*predicted_probs[0] + 1 - predicted_probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.80141881530018"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.012332908597145"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c *= (progressions[1]*predicted_probs[1] + 1 - predicted_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.064959349593496"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progressions[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "c *= predicted_probs[5] * progressions[5] + (1 - predicted_probs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.89426279984663"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_grid(data, model, features, target, window_size):\n",
    "      \n",
    "      # Initialiser les listes pour stocker les prédictions et les vraies valeurs\n",
    "      predictions = []\n",
    "      actuals = []\n",
    "\n",
    "      # Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\n",
    "      for i in range(window_size, len(data) - 1):\n",
    "            # Diviser les données en ensembles d'entraînement et de test\n",
    "            X_train = features.iloc[i-window_size:i, :]\n",
    "            y_train = target.iloc[i-window_size:i]\n",
    "            X_test = features.iloc[i:i+1, :]\n",
    "            y_test = target.iloc[i]\n",
    "\n",
    "            #Normaliser les données\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # Entraîner un modèle\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire une prédiction\n",
    "            prediction = model.predict(X_test)[0]\n",
    "            \n",
    "            # Stocker les prédictions et les vraies valeurs\n",
    "            predictions.append(prediction)\n",
    "            actuals.append(y_test)\n",
    "\n",
    "      # Évaluer le modèle\n",
    "      accuracy = accuracy_score(actuals, predictions)\n",
    "      return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la grille de paramètres\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [50, 100, 200, 500],\n",
    "    'fit_intercept': [True, False],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'newton-cg'}: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'lbfgs'}: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear'}, accuracy : 0.47766884531590414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'sag'}: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'saga'}, accuracy : 0.5217864923747276\n",
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'newton-cg'}, accuracy : 0.5296840958605664\n",
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear'}, accuracy : 0.5427559912854031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'elasticnet', 'solver': 'newton-cg'}: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'elasticnet', 'solver': 'lbfgs'}: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'elasticnet', 'solver': 'liblinear'}: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'elasticnet', 'solver': 'sag'}: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'none', 'solver': 'newton-cg'}, accuracy : 0.5642701525054467\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'none', 'solver': 'liblinear'}: penalty='none' is not supported for the liblinear solver</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 50, 'penalty': 'none', 'solver': 'sag'}, accuracy : 0.5650871459694989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'newton-cg'}: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'lbfgs'}: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'sag'}: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'newton-cg'}: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'lbfgs'}: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear'}: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'sag'}: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear'}: penalty='none' is not supported for the liblinear solver</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveaux meilleurs paramètres trouvés : {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 100, 'penalty': 'none', 'solver': 'sag'}, accuracy : 0.5675381263616558\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'newton-cg'}: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'lbfgs'}: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'sag'}: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'elasticnet', 'solver': 'newton-cg'}: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'elasticnet', 'solver': 'lbfgs'}: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'elasticnet', 'solver': 'liblinear'}: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'elasticnet', 'solver': 'sag'}: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<small>Error with parameters {'C': 0.001, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.1, 'max_iter': 200, 'penalty': 'none', 'solver': 'liblinear'}: penalty='none' is not supported for the liblinear solver</small>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thoma\\Desktop\\Code\\tradebtcai\\tests.ipynb Cellule 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model_instance \u001b[39m=\u001b[39m LogisticRegression(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Appliquer la fonction train_model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m accuracy \u001b[39m=\u001b[39m train_model_grid(data, model_instance, features, target, window_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Si le modèle actuel a une meilleure précision que le précédent meilleur modèle, stocker sa précision et ses paramètres\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m accuracy \u001b[39m>\u001b[39m best_accuracy:\n",
      "\u001b[1;32mc:\\Users\\thoma\\Desktop\\Code\\tradebtcai\\tests.ipynb Cellule 21\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Entraîner un modèle\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Faire une prédiction\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1303\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1304\u001b[0m     path_func(\n\u001b[0;32m   1305\u001b[0m         X,\n\u001b[0;32m   1306\u001b[0m         y,\n\u001b[0;32m   1307\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1308\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1309\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1310\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1311\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1312\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1313\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1314\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1315\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1316\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1317\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1318\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1319\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1320\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1321\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1322\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1323\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1324\u001b[0m     )\n\u001b[0;32m   1325\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1326\u001b[0m )\n\u001b[0;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:533\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    530\u001b[0m         alpha \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m l1_ratio)\n\u001b[0;32m    531\u001b[0m         beta \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C) \u001b[39m*\u001b[39m l1_ratio\n\u001b[1;32m--> 533\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[39m=\u001b[39m sag_solver(\n\u001b[0;32m    534\u001b[0m         X,\n\u001b[0;32m    535\u001b[0m         target,\n\u001b[0;32m    536\u001b[0m         sample_weight,\n\u001b[0;32m    537\u001b[0m         loss,\n\u001b[0;32m    538\u001b[0m         alpha,\n\u001b[0;32m    539\u001b[0m         beta,\n\u001b[0;32m    540\u001b[0m         max_iter,\n\u001b[0;32m    541\u001b[0m         tol,\n\u001b[0;32m    542\u001b[0m         verbose,\n\u001b[0;32m    543\u001b[0m         random_state,\n\u001b[0;32m    544\u001b[0m         \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    545\u001b[0m         max_squared_sum,\n\u001b[0;32m    546\u001b[0m         warm_start_sag,\n\u001b[0;32m    547\u001b[0m         is_saga\u001b[39m=\u001b[39;49m(solver \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    548\u001b[0m     )\n\u001b[0;32m    550\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    551\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msolver must be one of \u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msag\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m solver\n\u001b[0;32m    554\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\thoma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:325\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCurrent sag implementation does not handle \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    324\u001b[0m sag \u001b[39m=\u001b[39m sag64 \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mfloat64 \u001b[39melse\u001b[39;00m sag32\n\u001b[1;32m--> 325\u001b[0m num_seen, n_iter_ \u001b[39m=\u001b[39m sag(\n\u001b[0;32m    326\u001b[0m     dataset,\n\u001b[0;32m    327\u001b[0m     coef_init,\n\u001b[0;32m    328\u001b[0m     intercept_init,\n\u001b[0;32m    329\u001b[0m     n_samples,\n\u001b[0;32m    330\u001b[0m     n_features,\n\u001b[0;32m    331\u001b[0m     n_classes,\n\u001b[0;32m    332\u001b[0m     tol,\n\u001b[0;32m    333\u001b[0m     max_iter,\n\u001b[0;32m    334\u001b[0m     loss,\n\u001b[0;32m    335\u001b[0m     step_size,\n\u001b[0;32m    336\u001b[0m     alpha_scaled,\n\u001b[0;32m    337\u001b[0m     beta_scaled,\n\u001b[0;32m    338\u001b[0m     sum_gradient_init,\n\u001b[0;32m    339\u001b[0m     gradient_memory_init,\n\u001b[0;32m    340\u001b[0m     seen_init,\n\u001b[0;32m    341\u001b[0m     num_seen_init,\n\u001b[0;32m    342\u001b[0m     fit_intercept,\n\u001b[0;32m    343\u001b[0m     intercept_sum_gradient,\n\u001b[0;32m    344\u001b[0m     intercept_decay,\n\u001b[0;32m    345\u001b[0m     is_saga,\n\u001b[0;32m    346\u001b[0m     verbose,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    349\u001b[0m \u001b[39mif\u001b[39;00m n_iter_ \u001b[39m==\u001b[39m max_iter:\n\u001b[0;32m    350\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    351\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    352\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    353\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# Créer une liste de combinaisons de paramètres\n",
    "grid_list = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Pour boucler sur chaque combinaison :\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "\n",
    "for params in grid_list:\n",
    "    try:\n",
    "        # Instancier le modèle avec les paramètres\n",
    "        model_instance = LogisticRegression(**params)\n",
    "        \n",
    "        # Appliquer la fonction train_model\n",
    "        accuracy = train_model_grid(data, model_instance, features, target, window_size)\n",
    "        \n",
    "        # Si le modèle actuel a une meilleure précision que le précédent meilleur modèle, stocker sa précision et ses paramètres\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = params\n",
    "            print(f\"Nouveaux meilleurs paramètres trouvés : {params}, accuracy : {accuracy}\")\n",
    "\n",
    "        \n",
    "            \n",
    "    except Exception as e:\n",
    "        # Gérer les combinaisons de paramètres non compatibles\n",
    "        error_message = f\"Error with parameters {params}: {e}\"\n",
    "        display(HTML(f\"<small>{error_message}</small>\"))\n",
    "        #pass\n",
    "\n",
    "print(f\"Best Model Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "print(f\"Best Parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 52.62%\n",
      "Total Cost of Misclassification: 5027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialiser les listes pour stocker les prédictions, les probabilités de prédiction et les vraies valeurs\n",
    "predictions = []\n",
    "prediction_probs = []\n",
    "actuals = []\n",
    "\n",
    "# Supposons que window_size et data sont définis\n",
    "window_size = 100  # exemple de taille de fenêtre\n",
    "\n",
    "# Boucle à travers les données de la taille de la fenêtre jusqu'à la fin des données\n",
    "for i in range(window_size, len(data) - 1):\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    X_train = features.iloc[i-window_size:i, :]\n",
    "    y_train = target.iloc[i-window_size:i]\n",
    "    X_test = features.iloc[i:i+1, :]\n",
    "    y_test = target.iloc[i]\n",
    "\n",
    "    \"\"\"#Normaliser les données\n",
    "    scaler = StandardScaler()\n",
    "    X_train_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\"\"\"\n",
    "\n",
    "    # Entraîner un modèle\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faire une prédiction\n",
    "    prediction = model.predict(X_test)[0]\n",
    "    prediction_prob = model.predict_proba(X_test)[0][1]  # probabilité de la classe 1\n",
    "    \n",
    "    # Stocker les prédictions, les probabilités de prédiction et les vraies valeurs\n",
    "    predictions.append(prediction)\n",
    "    prediction_probs.append(prediction_prob)\n",
    "    actuals.append(y_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Matrice de coût\n",
    "cost_matrix = np.array([[0, 1],  # coût de classer 0 comme 0/1\n",
    "                        [5, 0]])  # coût de classer 1 comme 0/1\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(actuals, predictions)\n",
    "\n",
    "# Coût total de mauvaise classification\n",
    "total_cost = np.sum(conf_matrix * cost_matrix)\n",
    "print(f'Total Cost of Misclassification: {total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
