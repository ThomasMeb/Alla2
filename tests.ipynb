{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=200\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/btc_data', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>progression daily</th>\n",
       "      <th>progression tomorrow</th>\n",
       "      <th>volumeto</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-29</th>\n",
       "      <td>141.960000</td>\n",
       "      <td>1.575032e+09</td>\n",
       "      <td>0.049224</td>\n",
       "      <td>-0.046915</td>\n",
       "      <td>9.983975e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-30</th>\n",
       "      <td>135.300000</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>-0.046915</td>\n",
       "      <td>-0.135255</td>\n",
       "      <td>9.119201e+06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>117.000000</td>\n",
       "      <td>1.298952e+09</td>\n",
       "      <td>-0.135255</td>\n",
       "      <td>-0.115983</td>\n",
       "      <td>2.178794e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-02</th>\n",
       "      <td>103.430000</td>\n",
       "      <td>1.148668e+09</td>\n",
       "      <td>-0.115983</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>2.493210e+07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-03</th>\n",
       "      <td>91.010000</td>\n",
       "      <td>1.011066e+09</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>0.222393</td>\n",
       "      <td>2.249626e+07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09</th>\n",
       "      <td>27948.103652</td>\n",
       "      <td>5.449897e+11</td>\n",
       "      <td>-0.001052</td>\n",
       "      <td>-0.012678</td>\n",
       "      <td>6.039641e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-10</th>\n",
       "      <td>27593.782534</td>\n",
       "      <td>5.382827e+11</td>\n",
       "      <td>-0.012678</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>5.111095e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-11</th>\n",
       "      <td>27392.247703</td>\n",
       "      <td>5.352004e+11</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.020081</td>\n",
       "      <td>8.213956e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-12</th>\n",
       "      <td>26842.190439</td>\n",
       "      <td>5.236564e+11</td>\n",
       "      <td>-0.020081</td>\n",
       "      <td>-0.004212</td>\n",
       "      <td>4.385320e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13</th>\n",
       "      <td>26729.137206</td>\n",
       "      <td>5.216077e+11</td>\n",
       "      <td>-0.004212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.171027e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3819 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   price    market_cap  progression daily  \\\n",
       "2013-04-29    141.960000  1.575032e+09           0.049224   \n",
       "2013-04-30    135.300000  1.501657e+09          -0.046915   \n",
       "2013-05-01    117.000000  1.298952e+09          -0.135255   \n",
       "2013-05-02    103.430000  1.148668e+09          -0.115983   \n",
       "2013-05-03     91.010000  1.011066e+09          -0.120081   \n",
       "...                  ...           ...                ...   \n",
       "2023-10-09  27948.103652  5.449897e+11          -0.001052   \n",
       "2023-10-10  27593.782534  5.382827e+11          -0.012678   \n",
       "2023-10-11  27392.247703  5.352004e+11          -0.007304   \n",
       "2023-10-12  26842.190439  5.236564e+11          -0.020081   \n",
       "2023-10-13  26729.137206  5.216077e+11          -0.004212   \n",
       "\n",
       "            progression tomorrow      volumeto  target  \n",
       "2013-04-29             -0.046915  9.983975e+06       0  \n",
       "2013-04-30             -0.135255  9.119201e+06       0  \n",
       "2013-05-01             -0.115983  2.178794e+07       0  \n",
       "2013-05-02             -0.120081  2.493210e+07       0  \n",
       "2013-05-03              0.222393  2.249626e+07       1  \n",
       "...                          ...           ...     ...  \n",
       "2023-10-09             -0.012678  6.039641e+08       0  \n",
       "2023-10-10             -0.007304  5.111095e+08       0  \n",
       "2023-10-11             -0.020081  8.213956e+08       0  \n",
       "2023-10-12             -0.004212  4.385320e+08       0  \n",
       "2023-10-13              0.000000  2.171027e+08       0  \n",
       "\n",
       "[3819 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['price_log'] = np.log(data['price'])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data['price_normalized'] = scaler.fit_transform(data[['price']])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data['price_standardized'] = scaler.fit_transform(data[['price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>progression daily</th>\n",
       "      <th>progression tomorrow</th>\n",
       "      <th>volumeto</th>\n",
       "      <th>target</th>\n",
       "      <th>price_log</th>\n",
       "      <th>price_normalized</th>\n",
       "      <th>price_standardized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-29</th>\n",
       "      <td>141.960000</td>\n",
       "      <td>1.575032e+09</td>\n",
       "      <td>0.049224</td>\n",
       "      <td>-0.046915</td>\n",
       "      <td>9.983975e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4.955545</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.776361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-30</th>\n",
       "      <td>135.300000</td>\n",
       "      <td>1.501657e+09</td>\n",
       "      <td>-0.046915</td>\n",
       "      <td>-0.135255</td>\n",
       "      <td>9.119201e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>4.907495</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>-0.776788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>117.000000</td>\n",
       "      <td>1.298952e+09</td>\n",
       "      <td>-0.135255</td>\n",
       "      <td>-0.115983</td>\n",
       "      <td>2.178794e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4.762174</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.777963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-02</th>\n",
       "      <td>103.430000</td>\n",
       "      <td>1.148668e+09</td>\n",
       "      <td>-0.115983</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>2.493210e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4.638895</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>-0.778834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-03</th>\n",
       "      <td>91.010000</td>\n",
       "      <td>1.011066e+09</td>\n",
       "      <td>-0.120081</td>\n",
       "      <td>0.222393</td>\n",
       "      <td>2.249626e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>4.510969</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.779631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09</th>\n",
       "      <td>27948.103652</td>\n",
       "      <td>5.449897e+11</td>\n",
       "      <td>-0.001052</td>\n",
       "      <td>-0.012678</td>\n",
       "      <td>6.039641e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>10.238105</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>1.008527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-10</th>\n",
       "      <td>27593.782534</td>\n",
       "      <td>5.382827e+11</td>\n",
       "      <td>-0.012678</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>5.111095e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>10.225346</td>\n",
       "      <td>0.407495</td>\n",
       "      <td>0.985783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-11</th>\n",
       "      <td>27392.247703</td>\n",
       "      <td>5.352004e+11</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.020081</td>\n",
       "      <td>8.213956e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>10.218015</td>\n",
       "      <td>0.404512</td>\n",
       "      <td>0.972847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-12</th>\n",
       "      <td>26842.190439</td>\n",
       "      <td>5.236564e+11</td>\n",
       "      <td>-0.020081</td>\n",
       "      <td>-0.004212</td>\n",
       "      <td>4.385320e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>10.197730</td>\n",
       "      <td>0.396369</td>\n",
       "      <td>0.937538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-13</th>\n",
       "      <td>26729.137206</td>\n",
       "      <td>5.216077e+11</td>\n",
       "      <td>-0.004212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.171027e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>10.193510</td>\n",
       "      <td>0.394695</td>\n",
       "      <td>0.930281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3819 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   price    market_cap  progression daily  \\\n",
       "2013-04-29    141.960000  1.575032e+09           0.049224   \n",
       "2013-04-30    135.300000  1.501657e+09          -0.046915   \n",
       "2013-05-01    117.000000  1.298952e+09          -0.135255   \n",
       "2013-05-02    103.430000  1.148668e+09          -0.115983   \n",
       "2013-05-03     91.010000  1.011066e+09          -0.120081   \n",
       "...                  ...           ...                ...   \n",
       "2023-10-09  27948.103652  5.449897e+11          -0.001052   \n",
       "2023-10-10  27593.782534  5.382827e+11          -0.012678   \n",
       "2023-10-11  27392.247703  5.352004e+11          -0.007304   \n",
       "2023-10-12  26842.190439  5.236564e+11          -0.020081   \n",
       "2023-10-13  26729.137206  5.216077e+11          -0.004212   \n",
       "\n",
       "            progression tomorrow      volumeto  target  price_log  \\\n",
       "2013-04-29             -0.046915  9.983975e+06       0   4.955545   \n",
       "2013-04-30             -0.135255  9.119201e+06       0   4.907495   \n",
       "2013-05-01             -0.115983  2.178794e+07       0   4.762174   \n",
       "2013-05-02             -0.120081  2.493210e+07       0   4.638895   \n",
       "2013-05-03              0.222393  2.249626e+07       1   4.510969   \n",
       "...                          ...           ...     ...        ...   \n",
       "2023-10-09             -0.012678  6.039641e+08       0  10.238105   \n",
       "2023-10-10             -0.007304  5.111095e+08       0  10.225346   \n",
       "2023-10-11             -0.020081  8.213956e+08       0  10.218015   \n",
       "2023-10-12             -0.004212  4.385320e+08       0  10.197730   \n",
       "2023-10-13              0.000000  2.171027e+08       0  10.193510   \n",
       "\n",
       "            price_normalized  price_standardized  \n",
       "2013-04-29          0.001098           -0.776361  \n",
       "2013-04-30          0.000999           -0.776788  \n",
       "2013-05-01          0.000728           -0.777963  \n",
       "2013-05-02          0.000527           -0.778834  \n",
       "2013-05-03          0.000343           -0.779631  \n",
       "...                      ...                 ...  \n",
       "2023-10-09          0.412741            1.008527  \n",
       "2023-10-10          0.407495            0.985783  \n",
       "2023-10-11          0.404512            0.972847  \n",
       "2023-10-12          0.396369            0.937538  \n",
       "2023-10-13          0.394695            0.930281  \n",
       "\n",
       "[3819 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3819.000000\n",
       "mean     12236.613558\n",
       "std      15580.688835\n",
       "min         67.809000\n",
       "25%        573.527400\n",
       "50%       6481.323142\n",
       "75%      19214.062986\n",
       "max      67617.015545\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er une variable cible binaire : 1 si la progression demain est positive, 0 sinon\n",
    "data['target'] = np.where(data['progression tomorrow'] > 0, 1, 0)\n",
    "\n",
    "# SÃ©lectionner les caractÃ©ristiques et exclure la derniÃ¨re ligne\n",
    "features = data.drop(columns=['progression tomorrow', 'target', 'price']).iloc[:-1, :]\n",
    "target = data['target'].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thoma\\Desktop\\Code\\tradebtcai\\tests.ipynb Cellule 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# EntraÃ®ner un modÃ¨le\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Faire une prÃ©diction\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thoma/Desktop/Code/tradebtcai/tests.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    460\u001b[0m )(\n\u001b[0;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    462\u001b[0m         t,\n\u001b[0;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    464\u001b[0m         X,\n\u001b[0;32m    465\u001b[0m         y,\n\u001b[0;32m    466\u001b[0m         sample_weight,\n\u001b[0;32m    467\u001b[0m         i,\n\u001b[0;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    472\u001b[0m     )\n\u001b[0;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# DÃ©finir la taille de la fenÃªtre initiale\n",
    "window_size = 1000  # par exemple\n",
    "\n",
    "# Initialiser les listes pour stocker les prÃ©dictions et les vraies valeurs\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "# Boucle Ã  travers les donnÃ©es de la taille de la fenÃªtre jusqu'Ã  la fin des donnÃ©es\n",
    "for i in range(window_size, len(data) - 1):\n",
    "    # Diviser les donnÃ©es en ensembles d'entraÃ®nement et de test\n",
    "    X_train = features.iloc[i-window_size:i, :]\n",
    "    y_train = target.iloc[i-window_size:i]\n",
    "    X_test = features.iloc[i:i+1, :]\n",
    "    y_test = target.iloc[i]\n",
    "    \n",
    "    # EntraÃ®ner un modÃ¨le\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faire une prÃ©diction\n",
    "    prediction = model.predict(X_test)[0]\n",
    "    \n",
    "    # Stocker les prÃ©dictions et les vraies valeurs\n",
    "    predictions.append(prediction)\n",
    "    actuals.append(y_test)\n",
    "\n",
    "# Ã‰valuer le modÃ¨le\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 53.02%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialiser les listes pour stocker les prÃ©dictions, les probabilitÃ©s de prÃ©diction et les vraies valeurs\n",
    "predictions = []\n",
    "prediction_probs = []\n",
    "actuals = []\n",
    "\n",
    "# Boucle Ã  travers les donnÃ©es de la taille de la fenÃªtre jusqu'Ã  la fin des donnÃ©es\n",
    "for i in range(window_size, len(data) - 1):\n",
    "    # Diviser les donnÃ©es en ensembles d'entraÃ®nement et de test\n",
    "    X_train = features.iloc[i-window_size:i, :]\n",
    "    y_train = target.iloc[i-window_size:i]\n",
    "    X_test = features.iloc[i:i+1, :]\n",
    "    y_test = target.iloc[i]\n",
    "    \n",
    "    # EntraÃ®ner un modÃ¨le\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faire une prÃ©diction\n",
    "    prediction = model.predict(X_test)[0]\n",
    "    prediction_prob = model.predict_proba(X_test)[0][1]  # probabilitÃ© de la classe 1\n",
    "    \n",
    "    # Stocker les prÃ©dictions, les probabilitÃ©s de prÃ©diction et les vraies valeurs\n",
    "    predictions.append(prediction)\n",
    "    prediction_probs.append(prediction_prob)\n",
    "    actuals.append(y_test)\n",
    "\n",
    "# Ã‰valuer le modÃ¨le\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 52.66%\n",
      "Total Cost of Misclassification: 5008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialiser les listes pour stocker les prÃ©dictions, les probabilitÃ©s de prÃ©diction et les vraies valeurs\n",
    "predictions = []\n",
    "prediction_probs = []\n",
    "actuals = []\n",
    "\n",
    "# Supposons que window_size et data sont dÃ©finis\n",
    "window_size = 100  # exemple de taille de fenÃªtre\n",
    "\n",
    "# Boucle Ã  travers les donnÃ©es de la taille de la fenÃªtre jusqu'Ã  la fin des donnÃ©es\n",
    "for i in range(window_size, len(data) - 1):\n",
    "    # Diviser les donnÃ©es en ensembles d'entraÃ®nement et de test\n",
    "    X_train = features.iloc[i-window_size:i, :]\n",
    "    y_train = target.iloc[i-window_size:i]\n",
    "    X_test = features.iloc[i:i+1, :]\n",
    "    y_test = target.iloc[i]\n",
    "    \n",
    "    # EntraÃ®ner un modÃ¨le\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Faire une prÃ©diction\n",
    "    prediction = model.predict(X_test)[0]\n",
    "    prediction_prob = model.predict_proba(X_test)[0][1]  # probabilitÃ© de la classe 1\n",
    "    \n",
    "    # Stocker les prÃ©dictions, les probabilitÃ©s de prÃ©diction et les vraies valeurs\n",
    "    predictions.append(prediction)\n",
    "    prediction_probs.append(prediction_prob)\n",
    "    actuals.append(y_test)\n",
    "\n",
    "# Ã‰valuer le modÃ¨le\n",
    "accuracy = accuracy_score(actuals, predictions)\n",
    "print(f'Model Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Matrice de coÃ»t\n",
    "cost_matrix = np.array([[0, 1],  # coÃ»t de classer 0 comme 0/1\n",
    "                        [5, 0]])  # coÃ»t de classer 1 comme 0/1\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix = confusion_matrix(actuals, predictions)\n",
    "\n",
    "# CoÃ»t total de mauvaise classification\n",
    "total_cost = np.sum(conf_matrix * cost_matrix)\n",
    "print(f'Total Cost of Misclassification: {total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
