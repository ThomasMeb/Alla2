{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=200\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/btc_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crop = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les caractéristiques et exclure la dernière ligne\n",
    "features = data_crop.drop(columns=['progression tomorrow', 'target', 'close', 'high', 'low', 'volumefrom']).iloc[:-1, :]\n",
    "target = data['target'].iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3825"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import os\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3800, Loss: 0.9602, Accuracy: 0.0000\n",
      "Step 3801, Loss: 0.8894, Accuracy: 0.0000\n",
      "Step 3802, Loss: 0.6581, Accuracy: 1.0000\n",
      "Step 3803, Loss: 0.7091, Accuracy: 0.0000\n",
      "Step 3804, Loss: 0.4818, Accuracy: 1.0000\n",
      "Step 3805, Loss: 1.4691, Accuracy: 0.0000\n",
      "Step 3806, Loss: 0.6157, Accuracy: 1.0000\n",
      "Step 3807, Loss: 0.8107, Accuracy: 0.0000\n",
      "Step 3808, Loss: 0.6844, Accuracy: 1.0000\n",
      "Step 3809, Loss: 2.6761, Accuracy: 0.0000\n",
      "Step 3810, Loss: 0.7100, Accuracy: 0.0000\n",
      "Step 3811, Loss: 0.4347, Accuracy: 1.0000\n",
      "Step 3812, Loss: 0.5534, Accuracy: 1.0000\n",
      "Step 3813, Loss: 0.5056, Accuracy: 1.0000\n",
      "Step 3814, Loss: 0.9862, Accuracy: 0.0000\n",
      "Step 3815, Loss: 0.6037, Accuracy: 1.0000\n",
      "Step 3816, Loss: 0.2259, Accuracy: 1.0000\n",
      "Step 3817, Loss: 1.4225, Accuracy: 0.0000\n",
      "Step 3818, Loss: 0.4067, Accuracy: 1.0000\n",
      "Step 3819, Loss: 0.3745, Accuracy: 1.0000\n",
      "Step 3820, Loss: 0.2248, Accuracy: 1.0000\n",
      "Step 3821, Loss: 1.6753, Accuracy: 0.0000\n",
      "Step 3822, Loss: 1.1853, Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 1. Préparation des données\n",
    "\n",
    "X = features.values\n",
    "y = target.values\n",
    "\n",
    "window_size = 1000 # Vous pouvez ajuster cette valeur selon vos besoins\n",
    "\n",
    "# 2. Construction du modèle\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(X.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Entraînement du modèle avec validation walk-forward\n",
    "\n",
    "for i in range(window_size, len(X) - 1):\n",
    "    # Séparation des données en ensembles d'entraînement et de test\n",
    "    X_train = X[i-window_size:i]\n",
    "    y_train = y[i-window_size:i]\n",
    "    X_test = X[i:i+1]\n",
    "    y_test = y[i:i+1]\n",
    "\n",
    "    # Normalisation des caractéristiques\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=0)  # Vous pouvez ajuster le nombre d'epochs selon vos besoins\n",
    "\n",
    "    # Évaluation du modèle (optionnel)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Step {i}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Earn Metric: 0.9799\n"
     ]
    }
   ],
   "source": [
    "# 1. Définir la métrique personnalisée\n",
    "\n",
    "def earn_metric(predicted_probs, progressions, n_days):\n",
    "    base = c = 1\n",
    "    for j in range(n_days):\n",
    "        index = len(predicted_probs) - n_days + j\n",
    "        c *= predicted_probs[index] * progressions[index] + (1 - predicted_probs[index])\n",
    "        base *= progressions[index]\n",
    "    return c / base\n",
    "\n",
    "# Préparation des données\n",
    "\n",
    "X = features.values\n",
    "y = target.values\n",
    "\n",
    "window_size = 2000  \n",
    "n_days = 30 \n",
    "\n",
    "# Construction du modèle\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(X.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Entraînement du modèle avec validation walk-forward\n",
    "\n",
    "predicted_probs = []\n",
    "progressions = []\n",
    "metrics = []\n",
    "\n",
    "for i in range(window_size, len(X) - 1 - n_days):\n",
    "    # Séparation des données\n",
    "    X_train = X[i-window_size:i]\n",
    "    y_train = y[i-window_size:i]\n",
    "    X_test = X[i:i+n_days]\n",
    "    y_test = y[i:i+n_days]\n",
    "\n",
    "    # Normalisation\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    with HiddenPrints():\n",
    "        # Entraînement\n",
    "        model.fit(X_train, y_train, epochs=20, verbose=0)\n",
    "\n",
    "        # Prédiction\n",
    "        predicted_prob = model.predict(X_test).flatten()\n",
    "        predicted_probs.extend(predicted_prob)\n",
    "\n",
    "    # Récupérer la progression réelle\n",
    "    progression = data_crop.iloc[i:i+n_days]['progression tomorrow'].values + 1\n",
    "    progressions.extend(progression)\n",
    "\n",
    "    # Calcul de la métrique personnalisée\n",
    "    if len(predicted_probs) >= n_days:\n",
    "        metric_value = earn_metric(predicted_probs, progressions, n_days)\n",
    "        metrics.append(metric_value)\n",
    "        #print(f\"Step {i}, Earn Metric: {metric_value:.4f}\")\n",
    "\n",
    "print(f\"Average Earn Metric: {np.mean(metrics):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
